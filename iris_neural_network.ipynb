{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "0             5.1          3.5           1.4          0.2     Setosa\n",
       "1             4.9          3.0           1.4          0.2     Setosa\n",
       "2             4.7          3.2           1.3          0.2     Setosa\n",
       "3             4.6          3.1           1.5          0.2     Setosa\n",
       "4             5.0          3.6           1.4          0.2     Setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# load data\n",
    "iris = pd.read_csv('iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set contains:  (96, 4) (96, 3)\n",
      "The validation set contains:  (24, 4) (30, 3)\n",
      "The testing set contains:  (30, 4) (30, 3)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "# Features matrix and label vector\n",
    "X = iris.iloc[:,:4].values.reshape(-1,4)\n",
    "y = iris.iloc[:,4].values\n",
    "y_enc = LabelEncoder().fit_transform(y)\n",
    "y_one_hot_label = tf.keras.utils.to_categorical(y_enc)\n",
    "\n",
    "# Training, testing and validation split\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y_one_hot_label, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"The training set contains: \", X_train.shape, y_train.shape)\n",
    "print(\"The validation set contains: \", X_val.shape, y_test.shape)\n",
    "print(\"The testing set contains: \", X_test.shape, y_test.shape)\n",
    "print(X_train.shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m40\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m15\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (364.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91\u001b[0m (364.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91</span> (364.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m91\u001b[0m (364.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]), # Input layer\n",
    "    keras.layers.Dense(8, activation=\"relu\"),\n",
    "    keras.layers.Dense(4, activation=\"relu\"),\n",
    "    keras.layers.Dense(3, activation=\"softmax\") # Ouput layer\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9831 - loss: 0.2071 - val_accuracy: 0.8750 - val_loss: 0.2885\n",
      "Epoch 2/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.2148 - val_accuracy: 0.8750 - val_loss: 0.2884\n",
      "Epoch 3/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9909 - loss: 0.2204 - val_accuracy: 0.8750 - val_loss: 0.2862\n",
      "Epoch 4/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.2156 - val_accuracy: 0.8750 - val_loss: 0.2819\n",
      "Epoch 5/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.2112 - val_accuracy: 0.8750 - val_loss: 0.2819\n",
      "Epoch 6/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.2183 - val_accuracy: 0.8750 - val_loss: 0.2817\n",
      "Epoch 7/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.1966 - val_accuracy: 0.8750 - val_loss: 0.2789\n",
      "Epoch 8/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.2169 - val_accuracy: 0.8750 - val_loss: 0.2798\n",
      "Epoch 9/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.1980 - val_accuracy: 0.8750 - val_loss: 0.2797\n",
      "Epoch 10/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.2047 - val_accuracy: 0.8750 - val_loss: 0.2765\n",
      "Epoch 11/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9831 - loss: 0.2075 - val_accuracy: 0.8750 - val_loss: 0.2718\n",
      "Epoch 12/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.1826 - val_accuracy: 0.8750 - val_loss: 0.2762\n",
      "Epoch 13/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.1973 - val_accuracy: 0.8750 - val_loss: 0.2750\n",
      "Epoch 14/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.2042 - val_accuracy: 0.8750 - val_loss: 0.2736\n",
      "Epoch 15/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9831 - loss: 0.2069 - val_accuracy: 0.8750 - val_loss: 0.2696\n",
      "Epoch 16/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.1951 - val_accuracy: 0.8750 - val_loss: 0.2647\n",
      "Epoch 17/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.2069 - val_accuracy: 0.8750 - val_loss: 0.2638\n",
      "Epoch 18/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.1817 - val_accuracy: 0.8750 - val_loss: 0.2665\n",
      "Epoch 19/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.1861 - val_accuracy: 0.8750 - val_loss: 0.2667\n",
      "Epoch 20/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.1833 - val_accuracy: 0.8750 - val_loss: 0.2697\n",
      "Epoch 21/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.1851 - val_accuracy: 0.8750 - val_loss: 0.2640\n",
      "Epoch 22/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.1709 - val_accuracy: 0.8750 - val_loss: 0.2632\n",
      "Epoch 23/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9909 - loss: 0.1962 - val_accuracy: 0.8750 - val_loss: 0.2623\n",
      "Epoch 24/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.1771 - val_accuracy: 0.8750 - val_loss: 0.2631\n",
      "Epoch 25/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.1917 - val_accuracy: 0.8750 - val_loss: 0.2576\n",
      "Epoch 26/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.1756 - val_accuracy: 0.8750 - val_loss: 0.2550\n",
      "Epoch 27/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.1787 - val_accuracy: 0.8750 - val_loss: 0.2572\n",
      "Epoch 28/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1880 - val_accuracy: 0.8750 - val_loss: 0.2560\n",
      "Epoch 29/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.1866 - val_accuracy: 0.8750 - val_loss: 0.2583\n",
      "Epoch 30/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.1654 - val_accuracy: 0.8750 - val_loss: 0.2606\n",
      "Epoch 31/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9831 - loss: 0.1739 - val_accuracy: 0.8750 - val_loss: 0.2587\n",
      "Epoch 32/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.1899 - val_accuracy: 0.8750 - val_loss: 0.2546\n",
      "Epoch 33/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9831 - loss: 0.1794 - val_accuracy: 0.8750 - val_loss: 0.2544\n",
      "Epoch 34/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9909 - loss: 0.1815 - val_accuracy: 0.8750 - val_loss: 0.2513\n",
      "Epoch 35/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1622 - val_accuracy: 0.8750 - val_loss: 0.2471\n",
      "Epoch 36/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.1649 - val_accuracy: 0.8750 - val_loss: 0.2500\n",
      "Epoch 37/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9948 - loss: 0.1641 - val_accuracy: 0.8750 - val_loss: 0.2489\n",
      "Epoch 38/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.1684 - val_accuracy: 0.8750 - val_loss: 0.2472\n",
      "Epoch 39/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.1537 - val_accuracy: 0.8750 - val_loss: 0.2479\n",
      "Epoch 40/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.1621 - val_accuracy: 0.8750 - val_loss: 0.2473\n",
      "Epoch 41/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.1634 - val_accuracy: 0.8750 - val_loss: 0.2477\n",
      "Epoch 42/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.1702 - val_accuracy: 0.8750 - val_loss: 0.2463\n",
      "Epoch 43/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.1671 - val_accuracy: 0.8750 - val_loss: 0.2401\n",
      "Epoch 44/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9909 - loss: 0.1596 - val_accuracy: 0.8750 - val_loss: 0.2401\n",
      "Epoch 45/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9909 - loss: 0.1524 - val_accuracy: 0.8750 - val_loss: 0.2387\n",
      "Epoch 46/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.1524 - val_accuracy: 0.8750 - val_loss: 0.2414\n",
      "Epoch 47/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.1678 - val_accuracy: 0.8750 - val_loss: 0.2435\n",
      "Epoch 48/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9909 - loss: 0.1478 - val_accuracy: 0.8750 - val_loss: 0.2436\n",
      "Epoch 49/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9831 - loss: 0.1698 - val_accuracy: 0.8750 - val_loss: 0.2405\n",
      "Epoch 50/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.1518 - val_accuracy: 0.8750 - val_loss: 0.2412\n",
      "Epoch 51/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.1454 - val_accuracy: 0.8750 - val_loss: 0.2412\n",
      "Epoch 52/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9948 - loss: 0.1453 - val_accuracy: 0.8750 - val_loss: 0.2371\n",
      "Epoch 53/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.1657 - val_accuracy: 0.8750 - val_loss: 0.2333\n",
      "Epoch 54/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9948 - loss: 0.1407 - val_accuracy: 0.8750 - val_loss: 0.2318\n",
      "Epoch 55/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.1510 - val_accuracy: 0.8750 - val_loss: 0.2314\n",
      "Epoch 56/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.1403 - val_accuracy: 0.8750 - val_loss: 0.2321\n",
      "Epoch 57/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.1370 - val_accuracy: 0.8750 - val_loss: 0.2355\n",
      "Epoch 58/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.1528 - val_accuracy: 0.8750 - val_loss: 0.2343\n",
      "Epoch 59/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9909 - loss: 0.1539 - val_accuracy: 0.8750 - val_loss: 0.2332\n",
      "Epoch 60/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9831 - loss: 0.1521 - val_accuracy: 0.8750 - val_loss: 0.2271\n",
      "Epoch 61/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.1417 - val_accuracy: 0.8750 - val_loss: 0.2297\n",
      "Epoch 62/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9948 - loss: 0.1258 - val_accuracy: 0.8750 - val_loss: 0.2310\n",
      "Epoch 63/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.1482 - val_accuracy: 0.8750 - val_loss: 0.2285\n",
      "Epoch 64/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9909 - loss: 0.1506 - val_accuracy: 0.8750 - val_loss: 0.2312\n",
      "Epoch 65/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.1422 - val_accuracy: 0.8750 - val_loss: 0.2333\n",
      "Epoch 66/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.1545 - val_accuracy: 0.8750 - val_loss: 0.2270\n",
      "Epoch 67/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.1344 - val_accuracy: 0.8750 - val_loss: 0.2293\n",
      "Epoch 68/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9831 - loss: 0.1574 - val_accuracy: 0.8750 - val_loss: 0.2236\n",
      "Epoch 69/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.1289 - val_accuracy: 0.9167 - val_loss: 0.2201\n",
      "Epoch 70/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.1345 - val_accuracy: 0.9167 - val_loss: 0.2219\n",
      "Epoch 71/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1399 - val_accuracy: 0.8750 - val_loss: 0.2257\n",
      "Epoch 72/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.1374 - val_accuracy: 0.8750 - val_loss: 0.2263\n",
      "Epoch 73/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9831 - loss: 0.1380 - val_accuracy: 0.8750 - val_loss: 0.2260\n",
      "Epoch 74/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.1273 - val_accuracy: 0.8750 - val_loss: 0.2262\n",
      "Epoch 75/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.1327 - val_accuracy: 0.8750 - val_loss: 0.2211\n",
      "Epoch 76/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9909 - loss: 0.1238 - val_accuracy: 0.8750 - val_loss: 0.2202\n",
      "Epoch 77/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.1378 - val_accuracy: 0.9167 - val_loss: 0.2189\n",
      "Epoch 78/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9909 - loss: 0.1263 - val_accuracy: 0.8750 - val_loss: 0.2204\n",
      "Epoch 79/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.1355 - val_accuracy: 0.8750 - val_loss: 0.2192\n",
      "Epoch 80/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9948 - loss: 0.1253 - val_accuracy: 0.8750 - val_loss: 0.2211\n",
      "Epoch 81/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9909 - loss: 0.1308 - val_accuracy: 0.8750 - val_loss: 0.2192\n",
      "Epoch 82/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9948 - loss: 0.1199 - val_accuracy: 0.8750 - val_loss: 0.2224\n",
      "Epoch 83/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.1197 - val_accuracy: 0.8750 - val_loss: 0.2200\n",
      "Epoch 84/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.1427 - val_accuracy: 0.9167 - val_loss: 0.2151\n",
      "Epoch 85/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.1306 - val_accuracy: 0.9167 - val_loss: 0.2152\n",
      "Epoch 86/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.1310 - val_accuracy: 0.9167 - val_loss: 0.2125\n",
      "Epoch 87/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.1231 - val_accuracy: 0.9167 - val_loss: 0.2134\n",
      "Epoch 88/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.1304 - val_accuracy: 0.8750 - val_loss: 0.2155\n",
      "Epoch 89/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.1221 - val_accuracy: 0.9167 - val_loss: 0.2126\n",
      "Epoch 90/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.1066 - val_accuracy: 0.8750 - val_loss: 0.2169\n",
      "Epoch 91/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1245 - val_accuracy: 0.8750 - val_loss: 0.2158\n",
      "Epoch 92/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.1318 - val_accuracy: 0.9167 - val_loss: 0.2123\n",
      "Epoch 93/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.1094 - val_accuracy: 0.8750 - val_loss: 0.2145\n",
      "Epoch 94/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.1262 - val_accuracy: 0.9167 - val_loss: 0.2126\n",
      "Epoch 95/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.1242 - val_accuracy: 0.9167 - val_loss: 0.2121\n",
      "Epoch 96/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.1084 - val_accuracy: 0.9167 - val_loss: 0.2083\n",
      "Epoch 97/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1190 - val_accuracy: 0.9167 - val_loss: 0.2067\n",
      "Epoch 98/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9948 - loss: 0.1134 - val_accuracy: 0.9167 - val_loss: 0.2117\n",
      "Epoch 99/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.1232 - val_accuracy: 0.8750 - val_loss: 0.2137\n",
      "Epoch 100/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9909 - loss: 0.1282 - val_accuracy: 0.8750 - val_loss: 0.2148\n",
      "Epoch 101/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.1054 - val_accuracy: 0.8750 - val_loss: 0.2147\n",
      "Epoch 102/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.1099 - val_accuracy: 0.8750 - val_loss: 0.2124\n",
      "Epoch 103/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.1248 - val_accuracy: 0.9167 - val_loss: 0.2081\n",
      "Epoch 104/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0994 - val_accuracy: 0.9167 - val_loss: 0.2024\n",
      "Epoch 105/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9948 - loss: 0.1094 - val_accuracy: 0.9167 - val_loss: 0.2011\n",
      "Epoch 106/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.1048 - val_accuracy: 0.9167 - val_loss: 0.2049\n",
      "Epoch 107/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9909 - loss: 0.1110 - val_accuracy: 0.8750 - val_loss: 0.2122\n",
      "Epoch 108/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.1056 - val_accuracy: 0.9167 - val_loss: 0.2087\n",
      "Epoch 109/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.1080 - val_accuracy: 0.9167 - val_loss: 0.2064\n",
      "Epoch 110/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9831 - loss: 0.1159 - val_accuracy: 0.9167 - val_loss: 0.2051\n",
      "Epoch 111/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.1232 - val_accuracy: 0.9167 - val_loss: 0.2014\n",
      "Epoch 112/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9948 - loss: 0.1065 - val_accuracy: 0.9167 - val_loss: 0.2041\n",
      "Epoch 113/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.1140 - val_accuracy: 0.9167 - val_loss: 0.2076\n",
      "Epoch 114/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.1162 - val_accuracy: 0.9167 - val_loss: 0.2059\n",
      "Epoch 115/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9909 - loss: 0.1045 - val_accuracy: 0.9167 - val_loss: 0.2074\n",
      "Epoch 116/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1177 - val_accuracy: 0.9167 - val_loss: 0.2043\n",
      "Epoch 117/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.1076 - val_accuracy: 0.9167 - val_loss: 0.2023\n",
      "Epoch 118/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9909 - loss: 0.1062 - val_accuracy: 0.9167 - val_loss: 0.2011\n",
      "Epoch 119/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.1038 - val_accuracy: 0.9167 - val_loss: 0.2023\n",
      "Epoch 120/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.1060 - val_accuracy: 0.9167 - val_loss: 0.2007\n",
      "Epoch 121/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9948 - loss: 0.0985 - val_accuracy: 0.9167 - val_loss: 0.2030\n",
      "Epoch 122/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9948 - loss: 0.1032 - val_accuracy: 0.9167 - val_loss: 0.2054\n",
      "Epoch 123/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9909 - loss: 0.1142 - val_accuracy: 0.9167 - val_loss: 0.2057\n",
      "Epoch 124/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9909 - loss: 0.1053 - val_accuracy: 0.9167 - val_loss: 0.2068\n",
      "Epoch 125/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9831 - loss: 0.1036 - val_accuracy: 0.9167 - val_loss: 0.1990\n",
      "Epoch 126/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.1032 - val_accuracy: 0.9167 - val_loss: 0.1962\n",
      "Epoch 127/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9948 - loss: 0.0990 - val_accuracy: 0.9167 - val_loss: 0.1923\n",
      "Epoch 128/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0990 - val_accuracy: 0.9167 - val_loss: 0.1988\n",
      "Epoch 129/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.1179 - val_accuracy: 0.9167 - val_loss: 0.1997\n",
      "Epoch 130/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.0973 - val_accuracy: 0.9167 - val_loss: 0.2031\n",
      "Epoch 131/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9909 - loss: 0.0988 - val_accuracy: 0.9167 - val_loss: 0.2009\n",
      "Epoch 132/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9948 - loss: 0.0886 - val_accuracy: 0.9167 - val_loss: 0.2024\n",
      "Epoch 133/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0998 - val_accuracy: 0.9167 - val_loss: 0.2025\n",
      "Epoch 134/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.1110 - val_accuracy: 0.9167 - val_loss: 0.1978\n",
      "Epoch 135/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9831 - loss: 0.1054 - val_accuracy: 0.9167 - val_loss: 0.1912\n",
      "Epoch 136/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.1017 - val_accuracy: 0.9167 - val_loss: 0.1940\n",
      "Epoch 137/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9948 - loss: 0.0875 - val_accuracy: 0.9167 - val_loss: 0.1970\n",
      "Epoch 138/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.0889 - val_accuracy: 0.9167 - val_loss: 0.2002\n",
      "Epoch 139/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0930 - val_accuracy: 0.9167 - val_loss: 0.2005\n",
      "Epoch 140/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.1052 - val_accuracy: 0.9167 - val_loss: 0.1982\n",
      "Epoch 141/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.1096 - val_accuracy: 0.9167 - val_loss: 0.1972\n",
      "Epoch 142/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0980 - val_accuracy: 0.9167 - val_loss: 0.1975\n",
      "Epoch 143/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0870 - val_accuracy: 0.9167 - val_loss: 0.1957\n",
      "Epoch 144/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.0900 - val_accuracy: 0.9167 - val_loss: 0.1968\n",
      "Epoch 145/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0948 - val_accuracy: 0.9167 - val_loss: 0.1978\n",
      "Epoch 146/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.0896 - val_accuracy: 0.9167 - val_loss: 0.1974\n",
      "Epoch 147/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0855 - val_accuracy: 0.9167 - val_loss: 0.1974\n",
      "Epoch 148/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0953 - val_accuracy: 0.9167 - val_loss: 0.1937\n",
      "Epoch 149/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0928 - val_accuracy: 0.9167 - val_loss: 0.1915\n",
      "Epoch 150/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0901 - val_accuracy: 0.9167 - val_loss: 0.1903\n",
      "Epoch 151/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0939 - val_accuracy: 0.9167 - val_loss: 0.1918\n",
      "Epoch 152/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.0865 - val_accuracy: 0.9167 - val_loss: 0.1974\n",
      "Epoch 153/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0803 - val_accuracy: 0.9167 - val_loss: 0.1981\n",
      "Epoch 154/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0881 - val_accuracy: 0.9167 - val_loss: 0.1959\n",
      "Epoch 155/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9831 - loss: 0.0918 - val_accuracy: 0.9167 - val_loss: 0.1904\n",
      "Epoch 156/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.0900 - val_accuracy: 0.9167 - val_loss: 0.1890\n",
      "Epoch 157/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0841 - val_accuracy: 0.9167 - val_loss: 0.1887\n",
      "Epoch 158/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0923 - val_accuracy: 0.9167 - val_loss: 0.1862\n",
      "Epoch 159/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.0874 - val_accuracy: 0.9167 - val_loss: 0.1930\n",
      "Epoch 160/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9909 - loss: 0.0833 - val_accuracy: 0.9167 - val_loss: 0.1956\n",
      "Epoch 161/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9909 - loss: 0.0847 - val_accuracy: 0.9167 - val_loss: 0.1967\n",
      "Epoch 162/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9909 - loss: 0.0917 - val_accuracy: 0.9167 - val_loss: 0.1937\n",
      "Epoch 163/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9948 - loss: 0.0929 - val_accuracy: 0.9167 - val_loss: 0.1957\n",
      "Epoch 164/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.0833 - val_accuracy: 0.9167 - val_loss: 0.1919\n",
      "Epoch 165/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.0818 - val_accuracy: 0.9167 - val_loss: 0.1937\n",
      "Epoch 166/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0901 - val_accuracy: 0.9167 - val_loss: 0.1933\n",
      "Epoch 167/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9831 - loss: 0.0989 - val_accuracy: 0.9167 - val_loss: 0.1902\n",
      "Epoch 168/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.0779 - val_accuracy: 0.9167 - val_loss: 0.1909\n",
      "Epoch 169/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.0950 - val_accuracy: 0.9167 - val_loss: 0.1896\n",
      "Epoch 170/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0760 - val_accuracy: 0.9167 - val_loss: 0.1904\n",
      "Epoch 171/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9831 - loss: 0.0929 - val_accuracy: 0.9167 - val_loss: 0.1866\n",
      "Epoch 172/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0857 - val_accuracy: 0.9167 - val_loss: 0.1914\n",
      "Epoch 173/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0888 - val_accuracy: 0.9167 - val_loss: 0.1912\n",
      "Epoch 174/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9909 - loss: 0.0807 - val_accuracy: 0.9167 - val_loss: 0.1905\n",
      "Epoch 175/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9831 - loss: 0.0948 - val_accuracy: 0.9167 - val_loss: 0.1882\n",
      "Epoch 176/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.0860 - val_accuracy: 0.9167 - val_loss: 0.1875\n",
      "Epoch 177/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0852 - val_accuracy: 0.9167 - val_loss: 0.1929\n",
      "Epoch 178/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.0731 - val_accuracy: 0.9167 - val_loss: 0.1934\n",
      "Epoch 179/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0838 - val_accuracy: 0.9167 - val_loss: 0.1909\n",
      "Epoch 180/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.0815 - val_accuracy: 0.9167 - val_loss: 0.1905\n",
      "Epoch 181/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9948 - loss: 0.0837 - val_accuracy: 0.9167 - val_loss: 0.1918\n",
      "Epoch 182/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.0880 - val_accuracy: 0.9167 - val_loss: 0.1916\n",
      "Epoch 183/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0783 - val_accuracy: 0.9167 - val_loss: 0.1877\n",
      "Epoch 184/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0762 - val_accuracy: 0.9167 - val_loss: 0.1869\n",
      "Epoch 185/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.0858 - val_accuracy: 0.9167 - val_loss: 0.1851\n",
      "Epoch 186/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0887 - val_accuracy: 0.9167 - val_loss: 0.1863\n",
      "Epoch 187/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9948 - loss: 0.0745 - val_accuracy: 0.9167 - val_loss: 0.1852\n",
      "Epoch 188/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0864 - val_accuracy: 0.9167 - val_loss: 0.1840\n",
      "Epoch 189/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9948 - loss: 0.0814 - val_accuracy: 0.9167 - val_loss: 0.1884\n",
      "Epoch 190/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0760 - val_accuracy: 0.9167 - val_loss: 0.1904\n",
      "Epoch 191/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.0715 - val_accuracy: 0.9167 - val_loss: 0.1906\n",
      "Epoch 192/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0668 - val_accuracy: 0.9167 - val_loss: 0.1939\n",
      "Epoch 193/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9909 - loss: 0.0720 - val_accuracy: 0.9167 - val_loss: 0.1907\n",
      "Epoch 194/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.0719 - val_accuracy: 0.9167 - val_loss: 0.1858\n",
      "Epoch 195/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0688 - val_accuracy: 0.9167 - val_loss: 0.1846\n",
      "Epoch 196/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0786 - val_accuracy: 0.9167 - val_loss: 0.1874\n",
      "Epoch 197/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0705 - val_accuracy: 0.9167 - val_loss: 0.1858\n",
      "Epoch 198/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0839 - val_accuracy: 0.9167 - val_loss: 0.1834\n",
      "Epoch 199/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0871 - val_accuracy: 0.9167 - val_loss: 0.1857\n",
      "Epoch 200/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9948 - loss: 0.0648 - val_accuracy: 0.9167 - val_loss: 0.1884\n",
      "Epoch 201/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0682 - val_accuracy: 0.9167 - val_loss: 0.1901\n",
      "Epoch 202/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9831 - loss: 0.0734 - val_accuracy: 0.9167 - val_loss: 0.1927\n",
      "Epoch 203/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9909 - loss: 0.0771 - val_accuracy: 0.9167 - val_loss: 0.1929\n",
      "Epoch 204/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0797 - val_accuracy: 0.9167 - val_loss: 0.1850\n",
      "Epoch 205/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0736 - val_accuracy: 0.9167 - val_loss: 0.1841\n",
      "Epoch 206/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9831 - loss: 0.0849 - val_accuracy: 0.9167 - val_loss: 0.1859\n",
      "Epoch 207/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0763 - val_accuracy: 0.9167 - val_loss: 0.1868\n",
      "Epoch 208/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0644 - val_accuracy: 0.9167 - val_loss: 0.1880\n",
      "Epoch 209/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0742 - val_accuracy: 0.9167 - val_loss: 0.1865\n",
      "Epoch 210/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0782 - val_accuracy: 0.9167 - val_loss: 0.1845\n",
      "Epoch 211/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0690 - val_accuracy: 0.9167 - val_loss: 0.1848\n",
      "Epoch 212/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0783 - val_accuracy: 0.9167 - val_loss: 0.1837\n",
      "Epoch 213/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9909 - loss: 0.0640 - val_accuracy: 0.9167 - val_loss: 0.1868\n",
      "Epoch 214/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0688 - val_accuracy: 0.9167 - val_loss: 0.1863\n",
      "Epoch 215/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9831 - loss: 0.0792 - val_accuracy: 0.9167 - val_loss: 0.1825\n",
      "Epoch 216/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0733 - val_accuracy: 0.9167 - val_loss: 0.1847\n",
      "Epoch 217/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9831 - loss: 0.0773 - val_accuracy: 0.9167 - val_loss: 0.1850\n",
      "Epoch 218/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9831 - loss: 0.0735 - val_accuracy: 0.9167 - val_loss: 0.1847\n",
      "Epoch 219/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9948 - loss: 0.0707 - val_accuracy: 0.9167 - val_loss: 0.1882\n",
      "Epoch 220/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9831 - loss: 0.0684 - val_accuracy: 0.9167 - val_loss: 0.1896\n",
      "Epoch 221/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0815 - val_accuracy: 0.9167 - val_loss: 0.1887\n",
      "Epoch 222/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.0677 - val_accuracy: 0.9167 - val_loss: 0.1885\n",
      "Epoch 223/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.0609 - val_accuracy: 0.9167 - val_loss: 0.1845\n",
      "Epoch 224/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.0753 - val_accuracy: 0.9167 - val_loss: 0.1836\n",
      "Epoch 225/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9948 - loss: 0.0711 - val_accuracy: 0.9167 - val_loss: 0.1827\n",
      "Epoch 226/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0694 - val_accuracy: 0.9167 - val_loss: 0.1888\n",
      "Epoch 227/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9909 - loss: 0.0624 - val_accuracy: 0.9167 - val_loss: 0.1853\n",
      "Epoch 228/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9948 - loss: 0.0624 - val_accuracy: 0.9167 - val_loss: 0.1861\n",
      "Epoch 229/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9909 - loss: 0.0719 - val_accuracy: 0.9167 - val_loss: 0.1802\n",
      "Epoch 230/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9831 - loss: 0.0651 - val_accuracy: 0.9167 - val_loss: 0.1792\n",
      "Epoch 231/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.0638 - val_accuracy: 0.9167 - val_loss: 0.1820\n",
      "Epoch 232/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9909 - loss: 0.0648 - val_accuracy: 0.9167 - val_loss: 0.1859\n",
      "Epoch 233/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9948 - loss: 0.0690 - val_accuracy: 0.9167 - val_loss: 0.1911\n",
      "Epoch 234/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.0674 - val_accuracy: 0.9167 - val_loss: 0.1894\n",
      "Epoch 235/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.0700 - val_accuracy: 0.9167 - val_loss: 0.1849\n",
      "Epoch 236/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0723 - val_accuracy: 0.9167 - val_loss: 0.1801\n",
      "Epoch 237/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0618 - val_accuracy: 0.9167 - val_loss: 0.1833\n",
      "Epoch 238/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0569 - val_accuracy: 0.9167 - val_loss: 0.1817\n",
      "Epoch 239/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9948 - loss: 0.0665 - val_accuracy: 0.9167 - val_loss: 0.1839\n",
      "Epoch 240/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.0650 - val_accuracy: 0.9167 - val_loss: 0.1833\n",
      "Epoch 241/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9909 - loss: 0.0659 - val_accuracy: 0.9167 - val_loss: 0.1861\n",
      "Epoch 242/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9831 - loss: 0.0708 - val_accuracy: 0.9167 - val_loss: 0.1825\n",
      "Epoch 243/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9948 - loss: 0.0587 - val_accuracy: 0.9167 - val_loss: 0.1849\n",
      "Epoch 244/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9948 - loss: 0.0655 - val_accuracy: 0.9167 - val_loss: 0.1878\n",
      "Epoch 245/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9909 - loss: 0.0609 - val_accuracy: 0.9167 - val_loss: 0.1905\n",
      "Epoch 246/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9831 - loss: 0.0754 - val_accuracy: 0.9167 - val_loss: 0.1863\n",
      "Epoch 247/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9948 - loss: 0.0526 - val_accuracy: 0.9167 - val_loss: 0.1843\n",
      "Epoch 248/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9909 - loss: 0.0586 - val_accuracy: 0.9167 - val_loss: 0.1823\n",
      "Epoch 249/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9948 - loss: 0.0593 - val_accuracy: 0.9167 - val_loss: 0.1840\n",
      "Epoch 250/250\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9831 - loss: 0.0671 - val_accuracy: 0.9167 - val_loss: 0.1801\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=250, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.27987320e-04, 8.97864997e-01, 1.01506896e-01],\n",
       "       [9.98944700e-01, 1.05533574e-03, 4.12348211e-10],\n",
       "       [2.52994425e-08, 4.23512515e-03, 9.95764852e-01],\n",
       "       [5.15197287e-04, 8.30982149e-01, 1.68502599e-01],\n",
       "       [5.87307499e-04, 9.30679381e-01, 6.87334016e-02],\n",
       "       [9.98505712e-01, 1.49436493e-03, 1.73962922e-09],\n",
       "       [4.16373787e-03, 9.90309894e-01, 5.52625488e-03],\n",
       "       [1.46964085e-05, 1.35133877e-01, 8.64851415e-01],\n",
       "       [4.14201844e-04, 5.25043070e-01, 4.74542618e-01],\n",
       "       [2.50288821e-03, 9.85915899e-01, 1.15811713e-02],\n",
       "       [3.14311837e-05, 2.39474788e-01, 7.60493696e-01],\n",
       "       [9.98036802e-01, 1.96305546e-03, 4.65353400e-09],\n",
       "       [9.99163687e-01, 8.36271967e-04, 4.08122119e-10],\n",
       "       [9.98119414e-01, 1.88059744e-03, 3.54313578e-09],\n",
       "       [9.97996867e-01, 2.00305483e-03, 1.99426187e-09],\n",
       "       [3.65653104e-04, 9.00358021e-01, 9.92762893e-02],\n",
       "       [2.37520695e-07, 8.28638300e-03, 9.91713345e-01],\n",
       "       [2.67784134e-03, 9.76252079e-01, 2.10700128e-02],\n",
       "       [5.84226393e-04, 8.16843450e-01, 1.82572290e-01],\n",
       "       [3.83730537e-07, 9.56480484e-03, 9.90434647e-01],\n",
       "       [9.96889412e-01, 3.11054732e-03, 9.96507055e-09],\n",
       "       [5.77570354e-05, 2.75538385e-01, 7.24403858e-01],\n",
       "       [9.97208178e-01, 2.79184943e-03, 6.87555568e-09],\n",
       "       [4.83260294e-07, 1.02473591e-02, 9.89752114e-01],\n",
       "       [5.25070300e-06, 2.26837635e-01, 7.73157120e-01],\n",
       "       [3.72191312e-06, 4.41644043e-02, 9.55831885e-01],\n",
       "       [7.26266933e-07, 1.15732141e-02, 9.88426089e-01],\n",
       "       [1.85993187e-07, 7.70154363e-03, 9.92298305e-01],\n",
       "       [9.97396469e-01, 2.60351459e-03, 9.95415927e-09],\n",
       "       [9.97301579e-01, 2.69833882e-03, 8.10759992e-09]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Predicting testing set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to classes\n",
    "y_pred_class = np.around(y_pred)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred_class)\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure()\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred_class, axis=1))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', fmt='.0f')\n",
    "ax.set_title('Confusion Matrix\\n\\n')\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
